{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d04dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f10e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d98aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04637b3e",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207ec813",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3,3),\n",
    "    strides=(1, 1),\n",
    "    activation='relu'\n",
    "    )\n",
    "\n",
    "inputs =  keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "base = base_model(inputs, training=False)\n",
    "\n",
    "vectors = keras.layers.MaxPooling2D(pool_size=(2,2))(base)\n",
    "\n",
    "flatvectors = keras.layers.Flatten()(vectors)\n",
    "\n",
    "inner = keras.layers.Dense(64, activation='relu')(flatvectors)\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(inner)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.002, momentum=0.8)\n",
    "\n",
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6525fd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 148, 148, 32]),\n",
       " TensorShape([None, 74, 74, 32]),\n",
       " TensorShape([None, 175232]),\n",
       " TensorShape([None, 64]),\n",
       " TensorShape([None, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.shape, vectors.shape, flatvectors.shape, inner.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978e20c3",
   "metadata": {},
   "source": [
    "**Q1. The best loss function for Binary Classification is _BinaryCrossentropy_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2c0599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11215873"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b73ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23927c53",
   "metadata": {},
   "source": [
    "**Q2. The total number of parameters of the model = 11,215,873**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344bd766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "819acef6",
   "metadata": {},
   "source": [
    "# Generators and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a98038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './cats_dogs_dataset/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eed7540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './cats_dogs_dataset/validation',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c1b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.6991 - accuracy: 0.5035 - val_loss: 0.6917 - val_accuracy: 0.5150\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.6892 - accuracy: 0.5350 - val_loss: 0.6867 - val_accuracy: 0.5380\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 126s 1s/step - loss: 0.6780 - accuracy: 0.5635 - val_loss: 0.6786 - val_accuracy: 0.5610\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 134s 1s/step - loss: 0.6737 - accuracy: 0.5805 - val_loss: 0.6794 - val_accuracy: 0.5540\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 100s 999ms/step - loss: 0.6698 - accuracy: 0.5945 - val_loss: 0.6572 - val_accuracy: 0.6110\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 99s 988ms/step - loss: 0.6657 - accuracy: 0.5865 - val_loss: 0.6630 - val_accuracy: 0.5970\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 95s 951ms/step - loss: 0.6625 - accuracy: 0.5945 - val_loss: 0.6591 - val_accuracy: 0.5700\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 98s 976ms/step - loss: 0.6463 - accuracy: 0.6105 - val_loss: 0.6495 - val_accuracy: 0.6020\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.6463 - accuracy: 0.6205 - val_loss: 0.6437 - val_accuracy: 0.6080\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 96s 957ms/step - loss: 0.6385 - accuracy: 0.6230 - val_loss: 0.6426 - val_accuracy: 0.6290\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94683f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.590499997138977"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8cb6a",
   "metadata": {},
   "source": [
    "**Q3. The median of training accuracy for this model is 0.59**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6010426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018399237730612097"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf92607b",
   "metadata": {},
   "source": [
    "**Q4. The standard deviation of training loss for this model is 0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461a15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a40b1dab",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c8216e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './cats_dogs_dataset/train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeca2d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.6695 - accuracy: 0.5815 - val_loss: 0.6403 - val_accuracy: 0.6220\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.6605 - accuracy: 0.5945 - val_loss: 0.6353 - val_accuracy: 0.6370\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6670 - accuracy: 0.5855 - val_loss: 0.6798 - val_accuracy: 0.5660\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6626 - accuracy: 0.5890 - val_loss: 0.6327 - val_accuracy: 0.6350\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.6671 - accuracy: 0.5975 - val_loss: 0.6355 - val_accuracy: 0.6430\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.6450 - accuracy: 0.6225 - val_loss: 0.6572 - val_accuracy: 0.5920\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 107s 1s/step - loss: 0.6667 - accuracy: 0.5775 - val_loss: 0.6302 - val_accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.6522 - accuracy: 0.6030 - val_loss: 0.6402 - val_accuracy: 0.6230\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.6508 - accuracy: 0.6000 - val_loss: 0.6224 - val_accuracy: 0.6560\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.6540 - accuracy: 0.6135 - val_loss: 0.6433 - val_accuracy: 0.6160\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d473f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6416960537433625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de84359",
   "metadata": {},
   "source": [
    "**Q5. The mean of validation loss for the model trained with augmentations is 0.64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "507fcd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.627400004863739"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(history.history['val_accuracy'][5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f16a19",
   "metadata": {},
   "source": [
    "**Q6. The average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations is 0.63**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e1ac3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
